{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":24845,"status":"ok","timestamp":1753929459956,"user":{"displayName":"SAI SIDDHARTH","userId":"12564639798813955886"},"user_tz":-330},"id":"1YXnXwAbVVfM"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import io\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1562,"status":"ok","timestamp":1753929461511,"user":{"displayName":"SAI SIDDHARTH","userId":"12564639798813955886"},"user_tz":-330},"id":"VRPSgijD4r2a"},"outputs":[],"source":["\n","with open('CUB_200_2011\\images.txt', 'r') as file:\n","    images = file.read()\n","\n","df = pd.read_csv(io.StringIO(images), sep=r\"\\s+\", usecols=[1], names=[\"full_path\"])\n","df[\"full_path\"] = df[\"full_path\"].apply(lambda x: \"CUB_200_2011/images/\" + x)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1334,"status":"ok","timestamp":1753929462848,"user":{"displayName":"SAI SIDDHARTH","userId":"12564639798813955886"},"user_tz":-330},"id":"2zv7tp-YSj8N","outputId":"6d968c54-7488-48f6-945a-ac5dada052a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["(200, 312)\n"]}],"source":["data = np.loadtxt('CUB_200_2011/attributes/class_attribute_labels_continuous.txt')\n","print(data.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(3677856, 5) 3677856\n"]}],"source":["img_att_data = np.loadtxt('CUB_200_2011/attributes/image_attribute_labels_clean.txt')\n","print(img_att_data.shape)   "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"]}],"source":["target_lables = np.zeros((11788, 312), dtype=int)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","for i in range(0, 11788):\n","    for j in range (0, 312):\n","        img_att_data[i*312 + j][] = \n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1753929463009,"user":{"displayName":"SAI SIDDHARTH","userId":"12564639798813955886"},"user_tz":-330},"id":"dL4XRDDYSmV-","outputId":"9f7aecfd-e044-4c30-8250-84600191cb27"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>full_path</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CUB_200_2011/images/001.Black_footed_Albatross...</td>\n","      <td>[0.0, 2.9197080292, 1.4598540146, 0.0, 59.8540...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CUB_200_2011/images/001.Black_footed_Albatross...</td>\n","      <td>[0.0, 2.9197080292, 1.4598540146, 0.0, 59.8540...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CUB_200_2011/images/001.Black_footed_Albatross...</td>\n","      <td>[0.0, 2.9197080292, 1.4598540146, 0.0, 59.8540...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CUB_200_2011/images/001.Black_footed_Albatross...</td>\n","      <td>[0.0, 2.9197080292, 1.4598540146, 0.0, 59.8540...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CUB_200_2011/images/001.Black_footed_Albatross...</td>\n","      <td>[0.0, 2.9197080292, 1.4598540146, 0.0, 59.8540...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           full_path  \\\n","0  CUB_200_2011/images/001.Black_footed_Albatross...   \n","1  CUB_200_2011/images/001.Black_footed_Albatross...   \n","2  CUB_200_2011/images/001.Black_footed_Albatross...   \n","3  CUB_200_2011/images/001.Black_footed_Albatross...   \n","4  CUB_200_2011/images/001.Black_footed_Albatross...   \n","\n","                                              target  \n","0  [0.0, 2.9197080292, 1.4598540146, 0.0, 59.8540...  \n","1  [0.0, 2.9197080292, 1.4598540146, 0.0, 59.8540...  \n","2  [0.0, 2.9197080292, 1.4598540146, 0.0, 59.8540...  \n","3  [0.0, 2.9197080292, 1.4598540146, 0.0, 59.8540...  \n","4  [0.0, 2.9197080292, 1.4598540146, 0.0, 59.8540...  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df['idx'] = pd.read_csv(io.StringIO(images), sep=r\"\\s+\", usecols=[1], names=[\"idx\"])\n","df['idx']  = df['idx'].apply(lambda x: int(x.split('.')[0]))\n","df['target'] = df['idx'].apply(lambda x : data[x-1])\n","df.drop(columns = ['idx'], inplace = True)\n","df.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1753929463050,"user":{"displayName":"SAI SIDDHARTH","userId":"12564639798813955886"},"user_tz":-330},"id":"fZyqe1ipSmz_"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","\n","        # Input size: (3, 224, 224)\n","        # After conv1 + pool1 → (32, 112, 112)\n","        # After conv2 + pool2 → (64, 56, 56)\n","        self.flattened_size = 64 * 56 * 56\n","\n","        self.fc1 = nn.Linear(self.flattened_size, 1024)\n","        self.fc2 = nn.Linear(1024, 512)\n","        self.fc3 = nn.Linear(512, 312)\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv1(x)))\n","        x = self.pool2(F.relu(self.conv2(x)))\n","        x = x.view(x.size(0), -1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1753929463052,"user":{"displayName":"SAI SIDDHARTH","userId":"12564639798813955886"},"user_tz":-330},"id":"GgnlB4scSm35"},"outputs":[],"source":["class BirdsAttributesDataset(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform or transforms.Compose([\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","        ])\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.df.iloc[idx]['full_path']\n","        image = Image.open(image_path).convert(\"RGB\")\n","        image = self.transform(image)\n","\n","        target = self.df.iloc[idx]['target']\n","        target = torch.tensor(target, dtype=torch.float32)\n","        return image, target"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2196,"status":"ok","timestamp":1753929465238,"user":{"displayName":"SAI SIDDHARTH","userId":"12564639798813955886"},"user_tz":-330},"id":"p7BOwoFSSm7P"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = CNN().to(device)\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# ---- Split the Dataset ----\n","train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# ---- Create Datasets and Dataloaders ----\n","train_dataset = BirdsAttributesDataset(train_df)\n","val_dataset = BirdsAttributesDataset(val_df)\n","\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"background_save":true},"id":"qj687uOXRqKW"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","[Epoch 1] Starting training...\n"]},{"name":"stderr","output_type":"stream","text":["c:\\ML_and_DL\\birds_species_classifier\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n","  warnings.warn(warn_msg)\n"]},{"name":"stdout","output_type":"stream","text":["  - Training batch 10/2358 completed\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     13\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m running_loss += loss.item()\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx + \u001b[32m1\u001b[39m) % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (batch_idx + \u001b[32m1\u001b[39m) == \u001b[38;5;28mlen\u001b[39m(train_loader):\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ML_and_DL\\birds_species_classifier\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ML_and_DL\\birds_species_classifier\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ML_and_DL\\birds_species_classifier\\env\\Lib\\site-packages\\torch\\optim\\adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ML_and_DL\\birds_species_classifier\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ML_and_DL\\birds_species_classifier\\env\\Lib\\site-packages\\torch\\optim\\adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ML_and_DL\\birds_species_classifier\\env\\Lib\\site-packages\\torch\\optim\\adam.py:416\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    413\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    414\u001b[39m             grad = grad.add(param, alpha=weight_decay)\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    417\u001b[39m     grad = torch.view_as_real(grad)\n\u001b[32m    418\u001b[39m     exp_avg = torch.view_as_real(exp_avg)\n","\u001b[31mKeyboardInterrupt\u001b[39m: "]}],"source":["epochs = 10\n","\n","for epoch in range(epochs):\n","    print(f\"\\n[Epoch {epoch+1}] Starting training...\")\n","    model.train()\n","    running_loss = 0.0\n","\n","    for batch_idx, (imgs, labels) in enumerate(train_loader):\n","        imgs, labels = imgs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(imgs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_loader):\n","            print(f\"  - Training batch {batch_idx + 1}/{len(train_loader)} completed\")\n","\n","    print(f\"[Epoch {epoch+1}] Training complete. Starting validation...\")\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for val_batch_idx, (imgs, labels) in enumerate(val_loader):\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            if (val_batch_idx + 1) % 10 == 0 or (val_batch_idx + 1) == len(val_loader):\n","                print(f\"  - Validation batch {val_batch_idx + 1}/{len(val_loader)} completed\")\n","\n","    print(f\"[Epoch {epoch+1}] Train Loss: {running_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f}\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"background_save":true},"id":"G5oiPrbsSnI0"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"egDCB87IRfaN"},"outputs":[{"ename":"ValueError","evalue":"mount failed","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2618457937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ... (your existing code for model definition, optimizer, criterion, etc.) ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["# import os\n","# from google.colab import drive\n","# drive.mount('/content/drive', force_remount=True)\n","\n","# # ... (your existing code for model definition, optimizer, criterion, etc.) ...\n","\n","# # Define a path in your Google Drive to save checkpoints\n","# # The \"Transport endpoint is not connected\" error typically occurs when the\n","# # connection to the mounted Google Drive is lost. Re-mounting the drive\n","# # and ensuring the path is correct usually resolves this issue.\n","# CHECKPOINT_DIR = \"/content/drive/My Drive/Your_Model_Checkpoints/\" # Customize this path\n","# os.makedirs(CHECKPOINT_DIR, exist_ok=True) # Create the directory if it doesn't exist\n","\n","# # Initialize start_epoch and best_val_loss (or your preferred metric)\n","# start_epoch = 0\n","# best_val_loss = float('inf') # Or initialize with a high value if you're tracking accuracy and want to save the best model\n","# epochs = 10\n","\n","# # Check if a checkpoint exists and load it to resume training\n","# checkpoint_path = os.path.join(CHECKPOINT_DIR, \"last_checkpoint.pth\") # Or choose a more descriptive name\n","# if os.path.exists(checkpoint_path):\n","#     print(f\"Loading checkpoint from {checkpoint_path}\")\n","#     checkpoint = torch.load(checkpoint_path)\n","#     model.load_state_dict(checkpoint['model_state_dict'])\n","#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","#     start_epoch = checkpoint['epoch'] + 1  # Resume from the next epoch\n","#     best_val_loss = checkpoint.get('best_val_loss', float('inf')) # Handle cases where best_val_loss might not be in older checkpoints\n","#     print(f\"Resuming training from epoch {start_epoch} with previous best validation loss: {best_val_loss:.4f}\")\n","# else:\n","#     print(\"No checkpoint found. Starting training from scratch.\")\n","\n","# # Your training loop\n","# for epoch in range(start_epoch, epochs): # Start from 'start_epoch'\n","#     print(f\"\\n[Epoch {epoch+1}] Starting training...\")\n","#     model.train()\n","#     running_loss = 0.0\n","\n","#     for batch_idx, (imgs, labels) in enumerate(train_loader):\n","#         imgs, labels = imgs.to(device), labels.to(device)\n","#         optimizer.zero_grad()\n","#         outputs = model(imgs)\n","#         loss = criterion(outputs, labels)\n","#         loss.backward()\n","#         optimizer.step()\n","#         running_loss += loss.item()\n","\n","#         if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_loader):\n","#             print(f\"  - Training batch {batch_idx + 1}/{len(train_loader)} completed\")\n","\n","#     train_loss = running_loss / len(train_loader)\n","#     print(f\"[Epoch {epoch+1}] Training complete. Starting validation...\")\n","\n","#     # Validation\n","#     model.eval()\n","#     val_loss = 0.0\n","#     with torch.no_grad():\n","#         for val_batch_idx, (imgs, labels) in enumerate(val_loader):\n","#             imgs, labels = imgs.to(device), labels.to(device)\n","#             outputs = model(imgs)\n","#             loss = criterion(outputs, labels)\n","#             val_loss += loss.item()\n","\n","#             if (val_batch_idx + 1) % 10 == 0 or (val_batch_idx + 1) == len(val_loader):\n","#                 print(f\"  - Validation batch {val_batch_idx + 1}/{len(val_loader)} completed\")\n","\n","#     current_val_loss = val_loss / len(val_loader)\n","#     print(f\"[Epoch {epoch+1}] Train Loss: {train_loss:.4f} | Val Loss: {current_val_loss:.4f}\")\n","\n","#     # Save checkpoint\n","#     checkpoint = {\n","#         'epoch': epoch,\n","#         'model_state_dict': model.state_dict(),\n","#         'optimizer_state_dict': optimizer.state_dict(),\n","#         'train_loss': train_loss,\n","#         'val_loss': current_val_loss,\n","#         'best_val_loss': best_val_loss # Store the best validation loss seen so far\n","#     }\n","#     torch.save(checkpoint, checkpoint_path)\n","#     print(f\"Checkpoint saved to {checkpoint_path}\")\n","\n","#     # Optionally, save the best model separately\n","#     if current_val_loss < best_val_loss:\n","#         best_val_loss = current_val_loss\n","#         best_model_path = os.path.join(CHECKPOINT_DIR, \"best_model.pth\")\n","#         torch.save(model.state_dict(), best_model_path) # Save only model weights for best model\n","#         print(f\"New best model saved to {best_model_path} with validation loss: {best_val_loss:.4f}\")\n","\n","# print(\"\\nTraining complete!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eTar-G9kUxG5"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNWE6onm3ZwKEBgsC69lTLR","gpuType":"T4","mount_file_id":"1FhgvgyFsw6C2I24ND36qxEy8ANX9N7gX","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
